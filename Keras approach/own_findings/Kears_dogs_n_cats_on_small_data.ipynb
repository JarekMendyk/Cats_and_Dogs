{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AN EXAMPLE HOW ImageDataGenerator works\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('dogs_and_cats/demo2/11535.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='dogs_and_cats/demo2', save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 23s - loss: 0.6987 - acc: 0.5120 - val_loss: 0.6669 - val_acc: 0.5813\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 15s - loss: 0.6790 - acc: 0.5895 - val_loss: 0.6360 - val_acc: 0.6175\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 14s - loss: 0.6431 - acc: 0.6405 - val_loss: 1.0731 - val_acc: 0.5312\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 14s - loss: 0.6114 - acc: 0.6625 - val_loss: 0.7183 - val_acc: 0.5825\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 15s - loss: 0.5904 - acc: 0.7130 - val_loss: 0.5914 - val_acc: 0.6813\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 14s - loss: 0.5606 - acc: 0.7180 - val_loss: 0.5221 - val_acc: 0.7488\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 15s - loss: 0.5421 - acc: 0.7355 - val_loss: 0.5762 - val_acc: 0.6825\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 14s - loss: 0.5422 - acc: 0.7330 - val_loss: 0.5621 - val_acc: 0.7163\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 15s - loss: 0.5201 - acc: 0.7450 - val_loss: 0.5067 - val_acc: 0.7438\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 14s - loss: 0.5079 - acc: 0.7535 - val_loss: 0.6060 - val_acc: 0.7137\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 14s - loss: 0.5069 - acc: 0.7650 - val_loss: 0.5210 - val_acc: 0.7600\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 14s - loss: 0.4807 - acc: 0.7790 - val_loss: 0.7236 - val_acc: 0.7212\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 14s - loss: 0.5000 - acc: 0.7675 - val_loss: 0.5279 - val_acc: 0.7600\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 14s - loss: 0.4916 - acc: 0.7820 - val_loss: 0.4833 - val_acc: 0.7825\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 14s - loss: 0.4771 - acc: 0.7875 - val_loss: 0.5404 - val_acc: 0.7388\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 14s - loss: 0.4689 - acc: 0.7890 - val_loss: 0.5255 - val_acc: 0.7438\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 14s - loss: 0.5080 - acc: 0.7860 - val_loss: 0.5942 - val_acc: 0.7150\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 14s - loss: 0.4500 - acc: 0.8060 - val_loss: 0.6727 - val_acc: 0.7500\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 14s - loss: 0.4720 - acc: 0.8065 - val_loss: 0.6217 - val_acc: 0.7450\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 14s - loss: 0.4724 - acc: 0.7960 - val_loss: 0.4843 - val_acc: 0.7700\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 14s - loss: 0.4624 - acc: 0.7970 - val_loss: 0.4669 - val_acc: 0.7775\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 14s - loss: 0.4254 - acc: 0.8075 - val_loss: 0.4867 - val_acc: 0.7950\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 14s - loss: 0.4537 - acc: 0.8040 - val_loss: 0.5399 - val_acc: 0.7625\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 14s - loss: 0.4313 - acc: 0.8135 - val_loss: 0.4841 - val_acc: 0.7750\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 14s - loss: 0.4510 - acc: 0.8090 - val_loss: 0.4718 - val_acc: 0.7662\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 14s - loss: 0.4401 - acc: 0.8120 - val_loss: 0.4978 - val_acc: 0.7575\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 14s - loss: 0.4359 - acc: 0.8090 - val_loss: 0.4437 - val_acc: 0.7825\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 14s - loss: 0.4343 - acc: 0.8115 - val_loss: 0.5853 - val_acc: 0.7300\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 14s - loss: 0.4318 - acc: 0.8190 - val_loss: 0.4136 - val_acc: 0.8175\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 14s - loss: 0.4288 - acc: 0.8085 - val_loss: 0.5478 - val_acc: 0.7400\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 15s - loss: 0.4247 - acc: 0.8195 - val_loss: 0.5101 - val_acc: 0.7538\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 14s - loss: 0.4173 - acc: 0.8275 - val_loss: 0.5443 - val_acc: 0.7875\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 14s - loss: 0.4298 - acc: 0.8215 - val_loss: 0.4720 - val_acc: 0.8000\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 14s - loss: 0.4341 - acc: 0.8135 - val_loss: 0.4886 - val_acc: 0.7925\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 14s - loss: 0.4479 - acc: 0.8090 - val_loss: 0.4601 - val_acc: 0.7963\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 14s - loss: 0.4637 - acc: 0.8145 - val_loss: 0.5627 - val_acc: 0.7875\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 14s - loss: 0.4415 - acc: 0.8160 - val_loss: 0.5026 - val_acc: 0.7475\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 15s - loss: 0.4438 - acc: 0.8130 - val_loss: 0.4534 - val_acc: 0.8150\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 14s - loss: 0.4451 - acc: 0.8175 - val_loss: 0.5812 - val_acc: 0.8013\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 14s - loss: 0.4386 - acc: 0.8100 - val_loss: 0.4347 - val_acc: 0.8137\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 14s - loss: 0.4299 - acc: 0.8245 - val_loss: 0.5189 - val_acc: 0.7738\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 15s - loss: 0.4234 - acc: 0.8165 - val_loss: 0.4584 - val_acc: 0.8000\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 14s - loss: 0.4268 - acc: 0.8220 - val_loss: 0.5096 - val_acc: 0.7575\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 15s - loss: 0.4479 - acc: 0.8145 - val_loss: 0.5553 - val_acc: 0.6825\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 14s - loss: 0.4370 - acc: 0.8160 - val_loss: 0.4768 - val_acc: 0.7825\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 15s - loss: 0.4288 - acc: 0.8160 - val_loss: 0.5933 - val_acc: 0.8013\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 14s - loss: 0.4214 - acc: 0.8230 - val_loss: 0.5152 - val_acc: 0.7738\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 14s - loss: 0.4280 - acc: 0.8215 - val_loss: 0.9831 - val_acc: 0.6587\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 14s - loss: 0.4477 - acc: 0.8110 - val_loss: 0.4640 - val_acc: 0.8000\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 14s - loss: 0.4349 - acc: 0.8240 - val_loss: 0.4640 - val_acc: 0.80132s - l\n"
     ]
    }
   ],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.  :\n",
    "\"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\"\n",
    "\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'dogs_and_cats/data_small/train'\n",
    "validation_data_dir = 'dogs_and_cats/data_small/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('dogs_and_cats/data_small/first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the bottleneck features of a pre-trained network: 90% accuracy in a minute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "\"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\"\n",
    "\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'dogs_and_cats/data_small/bottleneck_fc_model.h5'\n",
    "train_data_dir = 'dogs_and_cats/data_small/train'\n",
    "validation_data_dir = 'dogs_and_cats/data_small/validation'\n",
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 5000\n",
    "epochs = 50\n",
    "batch_size = 20 # was 16\n",
    "\n",
    "if nb_train_samples % batch_size != 0:\n",
    "    raise ArithmeticError(\n",
    "        \"nb_train_samples should be divisibe by batch_size.\\n\"\n",
    "        \"nb_train_samples is \"+str(nb_train_samples)+\", \"\n",
    "        \"but batch_size is \"+str(batch_size)+\".\"\n",
    "    )\n",
    "    \n",
    "if nb_validation_samples % batch_size != 0:\n",
    "    raise ArithmeticError(\n",
    "        \"nb_validation_samples should be divisibe by batch_size.\\n\"\n",
    "        \"nb_validation_samples is \"+str(nb_validation_samples)+\", \"\n",
    "        \"but batch_size is \"+str(batch_size)+\".\"\n",
    "    )\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('dogs_and_cats/data_small/bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('dogs_and_cats/data_small/bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    \n",
    "    train_data = np.load(open('dogs_and_cats/data_small/bottleneck_features_train.npy', 'rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "    \n",
    "    # print(\"train_data.shape: \" + str(train_data.shape))\n",
    "    # print(\"train_labels.shape: \" + str(train_labels.shape))\n",
    "\n",
    "    validation_data = np.load(open('dogs_and_cats/data_small/bottleneck_features_validation.npy', 'rb'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "    \n",
    "    # print(\"validation_data.shape: \" + str(validation_data.shape))\n",
    "    # print(\"validation_labels.shape: \" + str(validation_labels.shape))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "\n",
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scripts above and below differ only in paths to folders (data_small and split_data respectively) so they were merged in one file keras_dogs_n_cats_merged.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 10s - loss: 0.3863 - acc: 0.8477 - val_loss: 0.3327 - val_acc: 0.8752\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 10s - loss: 0.2797 - acc: 0.8906 - val_loss: 0.2517 - val_acc: 0.9006\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2558 - acc: 0.9019 - val_loss: 0.2427 - val_acc: 0.9108\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2406 - acc: 0.9087 - val_loss: 0.2734 - val_acc: 0.9064\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2302 - acc: 0.9126 - val_loss: 0.2414 - val_acc: 0.9128\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2198 - acc: 0.9190 - val_loss: 0.2789 - val_acc: 0.8990\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2096 - acc: 0.9222 - val_loss: 0.2714 - val_acc: 0.9126\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2050 - acc: 0.9254 - val_loss: 0.2663 - val_acc: 0.9100\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2034 - acc: 0.9274 - val_loss: 0.2779 - val_acc: 0.9060\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.2010 - acc: 0.9272 - val_loss: 0.2701 - val_acc: 0.9136\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1946 - acc: 0.9307 - val_loss: 0.2926 - val_acc: 0.9072\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1884 - acc: 0.9332 - val_loss: 0.3118 - val_acc: 0.9046\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1857 - acc: 0.9372 - val_loss: 0.2927 - val_acc: 0.9112\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1847 - acc: 0.9388 - val_loss: 0.3142 - val_acc: 0.9096\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1819 - acc: 0.9393 - val_loss: 0.3059 - val_acc: 0.9078\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1727 - acc: 0.9440 - val_loss: 0.3269 - val_acc: 0.9074\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1751 - acc: 0.9414 - val_loss: 0.3258 - val_acc: 0.9098\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1693 - acc: 0.9447 - val_loss: 0.3372 - val_acc: 0.9108\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1665 - acc: 0.9455 - val_loss: 0.3271 - val_acc: 0.9070\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1573 - acc: 0.9494 - val_loss: 0.3383 - val_acc: 0.9126\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1599 - acc: 0.9487 - val_loss: 0.3534 - val_acc: 0.9072\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1544 - acc: 0.9523 - val_loss: 0.3870 - val_acc: 0.9078\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1538 - acc: 0.9521 - val_loss: 0.4017 - val_acc: 0.9106\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1530 - acc: 0.9530 - val_loss: 0.4340 - val_acc: 0.9034\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1495 - acc: 0.9569 - val_loss: 0.4132 - val_acc: 0.9116\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1428 - acc: 0.9558 - val_loss: 0.4063 - val_acc: 0.9108\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1395 - acc: 0.9575 - val_loss: 0.4396 - val_acc: 0.9082\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1436 - acc: 0.9580 - val_loss: 0.4301 - val_acc: 0.9104\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1380 - acc: 0.9601 - val_loss: 0.4305 - val_acc: 0.9100\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1400 - acc: 0.9589 - val_loss: 0.4212 - val_acc: 0.9118\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1374 - acc: 0.9621 - val_loss: 0.4507 - val_acc: 0.9102\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1360 - acc: 0.9628 - val_loss: 0.4849 - val_acc: 0.9074\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1335 - acc: 0.9624 - val_loss: 0.4631 - val_acc: 0.9092\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1279 - acc: 0.9642 - val_loss: 0.4836 - val_acc: 0.9086\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1266 - acc: 0.9657 - val_loss: 0.5143 - val_acc: 0.9062\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1234 - acc: 0.9649 - val_loss: 0.4696 - val_acc: 0.9098\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1208 - acc: 0.9669 - val_loss: 0.5568 - val_acc: 0.9048\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1242 - acc: 0.9672 - val_loss: 0.5373 - val_acc: 0.9056\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1216 - acc: 0.9673 - val_loss: 0.5022 - val_acc: 0.9072\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 10s - loss: 0.1209 - acc: 0.9679 - val_loss: 0.4989 - val_acc: 0.9068\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 10s - loss: 0.1193 - acc: 0.9699 - val_loss: 0.5308 - val_acc: 0.9042\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 10s - loss: 0.1152 - acc: 0.9704 - val_loss: 0.5893 - val_acc: 0.9018\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1092 - acc: 0.9716 - val_loss: 0.5733 - val_acc: 0.9058\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1193 - acc: 0.9705 - val_loss: 0.5980 - val_acc: 0.9066\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1106 - acc: 0.9725 - val_loss: 0.5990 - val_acc: 0.9074\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1143 - acc: 0.9721 - val_loss: 0.5590 - val_acc: 0.9056\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1167 - acc: 0.9711 - val_loss: 0.5835 - val_acc: 0.9048\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1075 - acc: 0.9714 - val_loss: 0.5727 - val_acc: 0.9082\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 9s - loss: 0.1059 - acc: 0.9741 - val_loss: 0.5459 - val_acc: 0.9098\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 8s - loss: 0.1068 - acc: 0.9737 - val_loss: 0.5925 - val_acc: 0.9070\n"
     ]
    }
   ],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "\"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\"\n",
    "\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'dogs_and_cats/split_data/bottleneck_fc_model.h5'\n",
    "train_data_dir = 'dogs_and_cats/split_data/train'\n",
    "validation_data_dir = 'dogs_and_cats/split_data/validation'\n",
    "nb_train_samples = 20000\n",
    "nb_validation_samples = 5000\n",
    "epochs = 50\n",
    "batch_size = 20 # was 16\n",
    "\n",
    "if nb_train_samples % batch_size != 0:\n",
    "    raise ArithmeticError(\n",
    "        \"nb_train_samples should be divisibe by batch_size.\\n\"\n",
    "        \"nb_train_samples is \"+str(nb_train_samples)+\", \"\n",
    "        \"but batch_size is \"+str(batch_size)+\".\"\n",
    "    )\n",
    "    \n",
    "if nb_validation_samples % batch_size != 0:\n",
    "    raise ArithmeticError(\n",
    "        \"nb_validation_samples should be divisibe by batch_size.\\n\"\n",
    "        \"nb_validation_samples is \"+str(nb_validation_samples)+\", \"\n",
    "        \"but batch_size is \"+str(batch_size)+\".\"\n",
    "    )\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('dogs_and_cats/split_data/bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('dogs_and_cats/split_data/bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    \n",
    "    train_data = np.load(open('dogs_and_cats/split_data/bottleneck_features_train.npy', 'rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "    \n",
    "    # print(\"train_data.shape: \" + str(train_data.shape))\n",
    "    # print(\"train_labels.shape: \" + str(train_labels.shape))\n",
    "\n",
    "    validation_data = np.load(open('dogs_and_cats/split_data/bottleneck_features_validation.npy', 'rb'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "    \n",
    "    # print(\"validation_data.shape: \" + str(validation_data.shape))\n",
    "    # print(\"validation_labels.shape: \" + str(validation_labels.shape))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "\n",
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
